{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import socket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requestID': 'ce810f46-f93e-4bc4-85e8-0a22df93be07',\n",
       " 'clientContextID': 'xyz',\n",
       " 'signature': {'*': '*'},\n",
       " 'results': [{'$1': 1}],\n",
       " 'plans': {},\n",
       " 'status': 'success',\n",
       " 'metrics': {'elapsedTime': '108.352762ms',\n",
       "  'executionTime': '102.224543ms',\n",
       "  'resultCount': 1,\n",
       "  'resultSize': 15,\n",
       "  'processedObjects': 0}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = {'statement': 'select 1;', 'pretty': 'true', 'client_context_id': 'xyz'}\n",
    "response = requests.get('http://localhost:19002/query/service', params = payload)\n",
    "response.json()\n",
    "# row['metrics']['executionTime'] = float(row['metrics']['executionTime'].replace('ms', ''))\n",
    "# row['metrics']['executionTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask user for benchmark type (tiny or big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter tiny for tiny benchmark or large for large benchmark: tiny\n",
      "USE TinyBenchmark;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmarkType = input(\"Enter tiny for tiny benchmark or large for large benchmark: \")\n",
    "\n",
    "if benchmarkType == \"tiny\":\n",
    "    isTiny = True\n",
    "elif benchmarkType == \"large\":\n",
    "    isTiny = False\n",
    "else:\n",
    "    print(\"Input is invalid. Defaulting to tiny benchmark.\")\n",
    "    benchmarkType = \"tiny\"\n",
    "    isTiny = True\n",
    "\n",
    "if isTiny:\n",
    "    dataverse = \"USE TinyBenchmark;\"\n",
    "else:\n",
    "    dataverse = \"USE BigBenchmark;\"\n",
    "\n",
    "dataverse += \"\\n\"\n",
    "print(dataverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andretran/Documents/Projects/AsterixDB/'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd += \"/\"\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the path of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter address: 127.0.0.1\n",
      "127.0.0.1\n",
      "/Users/andretran/Documents/Projects/AsterixDB/datasets/\n"
     ]
    }
   ],
   "source": [
    "addr = input(\"Enter address: \")\n",
    "\n",
    "# print(ip)\n",
    "\n",
    "datasetsPath = ''\n",
    "\n",
    "if addr == '127.0.0.1':\n",
    "    datasetsPath = cwd + \"datasets/\"\n",
    "elif addr == '1':\n",
    "    datasetsPath = \"/local_data/downloads/datasets/\"\n",
    "else:\n",
    "    print(\"Address is not recognized. Defaulting to 127.0.0.1.\")\n",
    "    addr = '127.0.0.1'\n",
    "    datasetsPath = cwd + \"datasets/\"\n",
    "\n",
    "print(addr)\n",
    "print(datasetsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the queries based on if the benchmark is tiny or big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andretran/Documents/Projects/AsterixDB/queries/*.sql\n",
      "['/Users/andretran/Documents/Projects/AsterixDB/tinyQueries/1a_Create_All.sql', '/Users/andretran/Documents/Projects/AsterixDB/tinyQueries/2a_Load_All.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/3_Point-Count_Buildings.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/4_Point-Count_RoadNetwork.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/5_Point-Count_AllNodes.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/6_Equals_Polygon-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/tinyQueries/7a_Equals_Point-Point.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/8_Disjoint_Polygon-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/9_Intersects_Line-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/10_Intersects_Point-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/tinyQueries/11a_Intersects_Point-Line.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/12_Touches_Polygon-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/13_Touches_Line-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/14_Crosses_Line-Line.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/15_Crosses_Line-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/16_Overlaps_Polygon-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/17_Within_Polygon-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/18_Within_Line-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/19_Within_Point-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/20_Contains_Polygon-Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/21_Scan_Polygon.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/22_Scan_RoadNetwork.sql', '/Users/andretran/Documents/Projects/AsterixDB/tinyQueries/23a_Create_States.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/24_Range_Buildings-States.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/25_Range_RoadNetwork-States.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/26_Aggregate_Buildings-States.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/27_Aggregate_RoadNetwork-States.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/28_Aggregate_AllNodes-States.sql', '/Users/andretran/Documents/Projects/AsterixDB/tinyQueries/29a_Distance_Points-Points.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/30_Create_UrbanAreas.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/31_ReverseGeocoding_Point-UrbanAreas.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/32_ReverseGeocoding_Point-Street.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/33_MapSearch&Browsing_Point-BoundingBox.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/34_MapSearch&Browsing_Line-BoundingBox.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/35_MapSearch&Browsing_Polygon-BoundingBox.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/36_Land-Information-Management_Buildings-States.sql', '/Users/andretran/Documents/Projects/AsterixDB/queries/37_Land-Information-Management_Average-SqFt-Buildings-States.sql']\n"
     ]
    }
   ],
   "source": [
    "# path = '/Users/andretran/Documents/Projects/AsterixDB/'\n",
    "sqlExt = \"*.sql\"\n",
    "queriesPath = cwd + \"queries/\" + sqlExt\n",
    "print(queriesPath)\n",
    "tinyQueriesPath = cwd + \"tinyQueries/\" + sqlExt\n",
    "bigQueriesPath = cwd + \"bigQueries/\" + sqlExt\n",
    "\n",
    "queries = glob.glob(queriesPath)\n",
    "tinyQueries = glob.glob(tinyQueriesPath)\n",
    "bigQueries = glob.glob(bigQueriesPath)\n",
    "\n",
    "if isTiny:\n",
    "    benchmarkQueries = queries + tinyQueries\n",
    "else:\n",
    "    benchmarkQueries = queries + bigQueries\n",
    "\n",
    "benchmarkQueries = natsorted(benchmarkQueries, key=os.path.basename)\n",
    "print(benchmarkQueries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a results folder to store benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/Users/andretran/Documents/Projects/AsterixDB/results/\n"
     ]
    }
   ],
   "source": [
    "resultsPath = cwd + 'results/'\n",
    "\n",
    "isExists = os.path.exists(resultsPath)\n",
    "print(isExists)\n",
    "\n",
    "if not isExists:\n",
    "    os.makedirs(path)\n",
    "    print(\"results directory created\")\n",
    "print(resultsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create json and csv files which will hold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created\n",
      "CSV file created\n"
     ]
    }
   ],
   "source": [
    "# Import Module\n",
    "\n",
    "# Folder Path\n",
    "# path = \"/Users/andretran/Documents/Projects/AsterixDB/queries\"\n",
    "\n",
    "# all_files = glob.glob('/Users/andretran/Documents/Projects/AsterixDB/queries/*.sql')\n",
    "\n",
    "# Change the directory\n",
    "# os.chdir(resultsPath)\n",
    "# if os.path.exists(cwd + 'results/'):\n",
    "\n",
    "dateString = datetime.utcnow().strftime('%Y-%m-%d %H_%M_%S.%f')[:-3]\n",
    "jsonFile = resultsPath + benchmarkType + \"_\" + dateString + \".json\"\n",
    "csvFile = resultsPath + benchmarkType + \"_\" + dateString + \".csv\"\n",
    "\n",
    "def create_json_file():\n",
    "    if os.path.exists(jsonFile):\n",
    "        os.remove(jsonFile)\n",
    "        print('JSON file deleted')\n",
    "    with open(jsonFile, mode='w', encoding='utf-8') as f:\n",
    "        json.dump([], f)\n",
    "        print('JSON file created')\n",
    "        \n",
    "def create_csv_file():\n",
    "    if os.path.exists(csvFile):\n",
    "        os.remove(csvFile)\n",
    "        print('CSV file deleted')\n",
    "    with open(csvFile, mode='w', encoding='utf-8') as f:\n",
    "        header = ['requestID', 'clientContextID', 'status', 'elapsedTime', 'resultCount', 'resultSize', 'processedObjects', 'timestamp']\n",
    "        writer = csv.writer(f)\n",
    "        # write the header\n",
    "        writer.writerow(header)\n",
    "        print('CSV file created')\n",
    "        \n",
    "create_json_file()\n",
    "create_csv_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the benchmark and save results to csv and json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a_Create_All.sql\n",
      "DROP DATAVERSE TinyBenchmark IF EXISTS;\n",
      "CREATE DATAVERSE TinyBenchmark;\n",
      "USE TinyBenchmark;\n",
      "\n",
      "CREATE TYPE RoadNetworkType AS {\n",
      "\tid: UUID,\n",
      "\tg: geometry,\n",
      "\tattr0: string?,\n",
      "\tattr1: string?,\n",
      "\tattr2: string?,\n",
      "\tattr3: string?,\n",
      "\tattr4: string?\n",
      "};\n",
      "\n",
      "CREATE TYPE BuildingsType AS {\n",
      "\tid: UUID,\n",
      "\tg: geometry,\n",
      "\tattr0: string?,\n",
      "\tattr1: string?\n",
      "};\n",
      "\n",
      "CREATE TYPE AllNodesType AS {\n",
      "\tid: UUID,\n",
      "\tg: geometry,\n",
      "\tattr0: string?,\n",
      "\tattr1: string?\n",
      "};\n",
      "\n",
      "CREATE DATASET RoadNetwork (RoadNetworkType) PRIMARY KEY id AUTOGENERATED;\n",
      "CREATE DATASET Buildings (BuildingsType) PRIMARY KEY id AUTOGENERATED;\n",
      "CREATE DATASET AllNodes (AllNodesType) PRIMARY KEY id AUTOGENERATED;\n",
      "CREATE DATASET TempAllNodes (AllNodesType) PRIMARY KEY id AUTOGENERATED;\n",
      "CREATE DATASET TempRoadNetwork (RoadNetworkType) PRIMARY KEY id AUTOGENERATED;\n",
      "success\n",
      "2a_Load_All.sql\n",
      "USE TinyBenchmark;\n",
      "-- USE TinyBenchmark;\n",
      "\n",
      "-- 'path'='127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/OSM2015_road-network.json'\n",
      "\n",
      "LOAD DATASET RoadNetwork using localfs\n",
      "(('path'= '127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/OSM2015_road-network.json'),\n",
      "('format'='adm'));\n",
      "\n",
      "LOAD DATASET Buildings using localfs\n",
      "(('path'= '127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/OSM2015_buildings.json'),\n",
      "('format'='adm'));\n",
      "\n",
      "LOAD DATASET AllNodes using localfs\n",
      "(('path'= '127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/OSM2015_all_nodes.json'),\n",
      "('format'='adm'));\n",
      "\n",
      "LOAD DATASET TempAllNodes using localfs\n",
      "(('path'= '127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/OSM2015_all_nodes_SN.json'),\n",
      "('format'='adm'));\n",
      "\n",
      "LOAD DATASET TempRoadNetwork using localfs\n",
      "(('path'= '127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/OSM2015_road-network_SN.json'),\n",
      "('format'='adm'));\n",
      "success\n",
      "3_Point-Count_Buildings.sql\n",
      "USE TinyBenchmark;\n",
      "Select st_n_points(Buildings.g)\n",
      "From Buildings;\n",
      "success\n",
      "4_Point-Count_RoadNetwork.sql\n",
      "USE TinyBenchmark;\n",
      "Select st_n_points(RoadNetwork.g)\n",
      "From RoadNetwork;\n",
      "success\n",
      "5_Point-Count_AllNodes.sql\n",
      "USE TinyBenchmark;\n",
      "Select st_n_points(AllNodes.g)\n",
      "From AllNodes;\n",
      "success\n",
      "6_Equals_Polygon-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings as B1, Buildings as B2\n",
      "WHERE st_equals(B1.g, B2.g)\n",
      "success\n",
      "7a_Equals_Point-Point.sql\n",
      "USE TinyBenchmark;\n",
      "-- USE TinyBenchmark;\n",
      "\n",
      "SELECT *\n",
      "FROM TempAllNodes as TAN1, TempAllNodes as TAN2\n",
      "WHERE st_equals(TAN1.g, TAN2.g)\n",
      "success\n",
      "8_Disjoint_Polygon-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings as B1, Buildings as B2\n",
      "WHERE st_disjoint(B1.g, B2.g)\n",
      "success\n",
      "9_Intersects_Line-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings, RoadNetwork\n",
      "WHERE st_intersects(Buildings.g, RoadNetwork.g)\n",
      "success\n",
      "10_Intersects_Point-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM AllNodes, Buildings\n",
      "WHERE st_intersects(AllNodes.g, Buildings.g)\n",
      "success\n",
      "11a_Intersects_Point-Line.sql\n",
      "USE TinyBenchmark;\n",
      "-- USE TinyBenchmark;\n",
      "\n",
      "SELECT *\n",
      "FROM TempAllNodes, TempRoadNetwork\n",
      "WHERE st_intersects(TempAllNodes.g, TempRoadNetwork.g)\n",
      "success\n",
      "12_Touches_Polygon-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings as B1, Buildings as B2\n",
      "WHERE st_touches(B1.g, B2.g)\n",
      "success\n",
      "13_Touches_Line-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM RoadNetwork, Buildings\n",
      "WHERE st_touches(RoadNetwork.g, Buildings.g)\n",
      "success\n",
      "14_Crosses_Line-Line.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM RoadNetwork as RN1, RoadNetwork as RN2\n",
      "WHERE st_crosses(RN1.g, RN2.g)\n",
      "success\n",
      "15_Crosses_Line-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM RoadNetwork, Buildings\n",
      "WHERE st_crosses(RoadNetwork.g, Buildings.g)\n",
      "success\n",
      "16_Overlaps_Polygon-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings as B1, Buildings as B2\n",
      "WHERE st_overlaps(B1.g, B2.g)\n",
      "success\n",
      "17_Within_Polygon-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings as B1, Buildings as B2\n",
      "WHERE st_within(B1.g, B2.g)\n",
      "success\n",
      "18_Within_Line-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM RoadNetwork, Buildings\n",
      "WHERE st_within(RoadNetwork.g, Buildings.g)\n",
      "success\n",
      "19_Within_Point-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM AllNodes, Buildings\n",
      "WHERE st_within(AllNodes.g, Buildings.g)\n",
      "success\n",
      "20_Contains_Polygon-Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM Buildings as B1, Buildings as B2\n",
      "WHERE st_contains(B1.g, B2.g)\n",
      "success\n",
      "21_Scan_Polygon.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT st_area(Buildings.g)\n",
      "FROM Buildings;\n",
      "success\n",
      "22_Scan_RoadNetwork.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT st_length(RoadNetwork.g)\n",
      "FROM RoadNetwork;\n",
      "success\n",
      "23a_Create_States.sql\n",
      "USE TinyBenchmark;\n",
      "CREATE TYPE StateType AS{\n",
      "\tne_id : int,\n",
      "\tname: string,\n",
      "\tg : geometry\n",
      "};\n",
      "\n",
      "CREATE DATASET TempStates (StateType) PRIMARY KEY ne_id;\n",
      "CREATE DATASET States (StateType) PRIMARY KEY ne_id;\n",
      "\n",
      "LOAD DATASET TempStates using localfs\n",
      "(('path'='127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/NE_states_provinces.json'),\n",
      "('format'='adm'));\n",
      "\n",
      "INSERT INTO States\n",
      "(\n",
      "\tSELECT ne_id, name, g\n",
      "\tFROM TempStates\n",
      "\tWHERE name = \"California\"\n",
      ");\n",
      "success\n",
      "24_Range_Buildings-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT st_area(Buildings.g) as Area\n",
      "FROM Buildings, States\n",
      "WHERE st_within(Buildings.g, States.g)\n",
      "success\n",
      "25_Range_RoadNetwork-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT st_length(RoadNetwork.g) as Length\n",
      "FROM RoadNetwork, States\n",
      "WHERE st_within(RoadNetwork.g, States.g);\n",
      "success\n",
      "26_Aggregate_Buildings-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT States.name, SUM(st_area(Buildings.g)) as TotalArea\n",
      "FROM States, Buildings\n",
      "WHERE st_contains(States.g, Buildings.g)\n",
      "GROUP BY States.name\n",
      "success\n",
      "27_Aggregate_RoadNetwork-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT States.name, SUM(st_length(RoadNetwork.g)) as TotalLength\n",
      "FROM States, RoadNetwork\n",
      "WHERE st_contains(States.g, RoadNetwork.g)\n",
      "GROUP BY States.name\n",
      "success\n",
      "28_Aggregate_AllNodes-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT States.name, COUNT(*) as TotalPoints\n",
      "FROM States, AllNodes\n",
      "WHERE st_contains(States.g, AllNodes.g)\n",
      "GROUP BY States.name\n",
      "success\n",
      "29a_Distance_Points-Points.sql\n",
      "USE TinyBenchmark;\n",
      "-- USE TinyBenchmark;\n",
      "\n",
      "SELECT TAN1.id, COUNT(*) as NearbyNodes\n",
      "FROM TempAllNodes TAN1, TempAllNodes TAN2\n",
      "WHERE st_distance(TAN1.g, TAN2.g) <= 0.017435\n",
      "GROUP BY TAN1.id\n",
      "ORDER BY NearbyNodes DESC\n",
      "success\n",
      "30_Create_UrbanAreas.sql\n",
      "USE TinyBenchmark;\n",
      "CREATE TYPE UrbanAreasType AS {\n",
      " id: UUID,\n",
      " g: geometry?,\n",
      " scalerank: int?,\n",
      " featurecla: string?,\n",
      " area_sqkm: double?,\n",
      " min_zoom: double?\n",
      "};\n",
      "\n",
      "CREATE DATASET UrbanAreas (UrbanAreasType) PRIMARY KEY id AUTOGENERATED;\n",
      "\n",
      "LOAD DATASET UrbanAreas using localfs\n",
      "(('path'='127.0.0.1:///Users/andretran/Documents/Projects/AsterixDB/datasets/NE_urban_areas.json'),\n",
      "('format'='adm'));\n",
      "\n",
      "success\n",
      "31_ReverseGeocoding_Point-UrbanAreas.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT UrbanAreas.name\n",
      "FROM UrbanAreas\n",
      "WHERE st_contains(UrbanAreas.g, st_make_point(-118.32683220505714, 33.341658429469184))\n",
      "success\n",
      "32_ReverseGeocoding_Point-Street.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT RoadNetwork.id, RoadNetwork.g, st_distance(RoadNetwork.g, st_make_point(-118.32683220505714, 33.341658429469184)) AS distance\n",
      "FROM RoadNetwork\n",
      "ORDER BY distance ASC\n",
      "LIMIT 1\n",
      "success\n",
      "33_MapSearch&Browsing_Point-BoundingBox.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM AllNodes\n",
      "WHERE st_intersects(AllNodes.g, st_geom_from_text('POLYGON((-118.62762451171875 33.224903086263964, -117.12799072265625 33.224903086263964, -117.12799072265625 34.168635904722734, -118.62762451171875 34.168635904722734, -118.62762451171875 33.224903086263964))'))\n",
      "success\n",
      "34_MapSearch&Browsing_Line-BoundingBox.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT *\n",
      "FROM RoadNetwork\n",
      "WHERE st_intersects(RoadNetwork.g, st_geom_from_text('POLYGON((-118.62762451171875 33.224903086263964, -117.12799072265625 33.224903086263964, -117.12799072265625 34.168635904722734, -118.62762451171875 34.168635904722734, -118.62762451171875 33.224903086263964))'))\n",
      "success\n",
      "35_MapSearch&Browsing_Polygon-BoundingBox.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT * \n",
      "FROM Buildings\n",
      "WHERE st_intersects(Buildings.g, st_geom_from_text('POLYGON((-118.62762451171875 33.224903086263964, -117.12799072265625 33.224903086263964, -117.12799072265625 34.168635904722734, -118.62762451171875 34.168635904722734, -118.62762451171875 33.224903086263964))'))\n",
      "success\n",
      "36_Land-Information-Management_Buildings-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT States.name, COUNT(*) as TotalBuildings\n",
      "FROM States, Buildings\n",
      "WHERE st_contains(States.g, Buildings.g)\n",
      "GROUP BY States.name\n",
      "success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37_Land-Information-Management_Average-SqFt-Buildings-States.sql\n",
      "USE TinyBenchmark;\n",
      "SELECT States.name, AVG(st_area(Buildings.g)) as AvgArea\n",
      "FROM States, Buildings\n",
      "WHERE st_contains(States.g, Buildings.g)\n",
      "GROUP BY States.name\n",
      "success\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def benchmark_queries(file_path, index):\n",
    "    with open(file_path, 'r') as f:\n",
    "        statement = f.read()\n",
    "        if index != 0:\n",
    "            statement = dataverse + statement\n",
    "        if index == 22 or 1:\n",
    "            statement = statement.replace('$PATH$', addr + '://' + datasetsPath)\n",
    "            \n",
    "        print(statement)\n",
    "        payload = {'statement': statement, 'pretty': 'true', 'client_context_id': os.path.basename(file_path), 'readonly': False}\n",
    "        timestamp = datetime.now()\n",
    "        response = requests.post('http://localhost:19002/query/service', params = payload)\n",
    "        row = response.json()\n",
    "        print(row['status'])\n",
    "        with open(jsonFile, \"r\") as of:\n",
    "            data = json.load(of)\n",
    "        data.append(row)\n",
    "        with open(jsonFile, \"w\") as of:\n",
    "            json.dump(data, of)\n",
    "        with open(csvFile, mode='a', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([row['requestID'], row['clientContextID'], row['status'], row['metrics']['elapsedTime'], row['metrics']['resultCount'], row['metrics']['resultSize'], row['metrics']['processedObjects'], timestamp])\n",
    "\n",
    "\n",
    "# iterate through all file\n",
    "for index, file_path in enumerate(benchmarkQueries):\n",
    "    # Check whether file is in text format or not\n",
    "    print(os.path.basename(file_path))\n",
    "    benchmark_queries(file_path, index)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- uniqueID\n",
    "- clientCopntextID as filename\n",
    "- check for status if failed or success\n",
    "- elapsed time\n",
    "- timestamp\n",
    "\n",
    "- create sample output file (json and csv)\n",
    "\n",
    "- collect memory usage over time (timeseries)\n",
    "    - peak memory (how tight a process is in terms of memory comsumption)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc472b739ba3a1e45855b340d200d10d6b8eaf0a9c51ca945a5acc5b9d216ee5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
